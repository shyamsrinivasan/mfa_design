{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra, os, re, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "biomId = 'Biomass_Rt_Clim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelStart = cobra.io.load_json_model('../yeast_model/yeast_model/build_iRhto/output/rt_draft/rt_draft8C.json')\n",
    "modelStart.reactions.EX_glc__D_e.lower_bound = -10. # basis 10\n",
    "modelStart.reactions.EX_o2_e.lower_bound = -1000. # default\n",
    "pfba_M9 = cobra.flux_analysis.pfba(modelStart)\n",
    "gMinMedium = pfba_M9.fluxes[biomId]\n",
    "pfba_M9.fluxes.to_csv('./output/pfba/pfba_WT_M9.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7541272865518587"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gMinMedium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection of mutants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Essential rxns from essential gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ess = pd.read_csv('../yeast_model/yeast_model/build_iRhto/output/D3_gene_essentiality_prediction.csv',\n",
    "                     sep='\\t')\n",
    "df_ess.index = df_ess.gene_id.tolist()\n",
    "df_ess = df_ess[df_ess.essential == 'Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_ess = [g.id for g in modelStart.genes if g.id in df_ess.index]\n",
    "rxns_from_ess_gene = []\n",
    "\n",
    "model_raw = modelStart.copy()\n",
    "model = modelStart.copy()\n",
    "\n",
    "for gid in genes_ess:\n",
    "    g = model.genes.get_by_id(gid)\n",
    "    g.knock_out()\n",
    "    \n",
    "    for rxn in g.reactions:\n",
    "        if rxn.bounds != model_raw.reactions.get_by_id(rxn.id).bounds:\n",
    "            rxns_from_ess_gene.append(rxn.id)\n",
    "            \n",
    "    g.functional = True\n",
    "    for rxn in g.reactions:\n",
    "        rxn.bounds = model_raw.reactions.get_by_id(rxn.id).bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Exchange rxns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns_ex = [rxn.id for rxn in model.reactions if rxn.id[:3] == 'EX_']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Transport rxns (even GPR associated ones, relevant for cases where transport GPR is poorly characterized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns_tp = [rxn.id for rxn in model.reactions if rxn.subsystem == 'Transport']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Essential rxns in silico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 331/2171 [00:12<01:01, 30.00it/s]cobra/util/solver.py:408 \u001b[1;31mUserWarning\u001b[0m: solver status is 'infeasible'\n",
      "                                                   \r"
     ]
    }
   ],
   "source": [
    "model_raw = modelStart.copy()\n",
    "model = modelStart.copy()\n",
    "\n",
    "rxns_ess = []\n",
    "rxns_check = [rxn.id for rxn in model.reactions]\n",
    "for rxnid in tqdm(rxns_check, leave=False):\n",
    "    rxn = model.reactions.get_by_id(rxnid)\n",
    "    rxn.knock_out()\n",
    "    fbako = model.optimize()\n",
    "    if fbako.status in [None, 'infeasible']:\n",
    "        rxns_ess.append(rxn.id)\n",
    "    \n",
    "    if fbako.f < 0.25*gMinMedium:\n",
    "        rxns_ess.append(rxn.id)\n",
    "        \n",
    "    rxn.bounds = model_raw.reactions.get_by_id(rxn.id).bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/Step1_essential_rxns_iRhto1108.txt', 'w') as f:\n",
    "    f.write('\\n'.join(rxns_ess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/Step1_essential_rxns_iRhto1108.txt') as f:\n",
    "    rxns_ess = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) No GPR reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns_nogpr = [rxn.id for rxn in model.reactions if rxn.gene_reaction_rule in ['', 'UNKNOWN', 'SPONT', 'TRUE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Special case: pseudoreactions and ATPM maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns_spec = [rxn.id for rxn in model.reactions if rxn.subsystem == 'Pseudoreaction'] + ['ATPM_c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Use FVA to find zero flux reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns_model = [rxn.id for rxn in model.reactions]\n",
    "fva = cobra.flux_analysis.flux_variability_analysis(model,\n",
    "        fraction_of_optimum=0, reaction_list=rxns_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rxns_zero = fva[(fva.minimum.abs() < 1e-6) & (fva.maximum.abs() < 1e-6)].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.reactions) - len(rxns_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Alternative carbon metabolism'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reactions.ABTDD_c.subsystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather all reactions to be excluded from being KO for mutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns_excl = {\n",
    "    'Essential_in_vivo': rxns_from_ess_gene,\n",
    "    'Essential_in_silico': rxns_ess,\n",
    "    'Exchange': rxns_ex,\n",
    "    'Transport': rxns_tp,\n",
    "    'No_gpr': rxns_nogpr,\n",
    "    'Special_case': rxns_spec,\n",
    "    'Zero_fva_flux': rxns_zero\n",
    "}\n",
    "\n",
    "with open('./output/Step1_rxns_excluded.json', 'w') as f:\n",
    "    f.write(json.dumps(rxns_excl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run pFBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run and record flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/Step1_rxns_excluded.json') as f:\n",
    "    rxns_excl = json.load(f)\n",
    "rxns_check = [rxn.id for rxn in model.reactions if rxn.id not in sum(rxns_excl.values(), [])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    }
   ],
   "source": [
    "cols = ['WT'] + [i + '_ko' for i in rxns_check]\n",
    "rxns_all = [rxn.id for rxn in model.reactions]\n",
    "df_pfba = pd.DataFrame(index=rxns_all, columns=cols)\n",
    "\n",
    "model_raw = modelStart.copy()\n",
    "model = modelStart.copy()\n",
    "\n",
    "df_pfba.loc[rxns_all, 'WT'] = pfba_M9.fluxes[rxns_all]\n",
    "\n",
    "for rxnid in tqdm(rxns_check, leave=False):\n",
    "    rxn = model.reactions.get_by_id(rxnid)\n",
    "    rxn.knock_out()\n",
    "    try:\n",
    "        pfba = cobra.flux_analysis.pfba(model)\n",
    "    except:\n",
    "        pfba = cobra.flux_analysis.pfba(model, fraction_of_optimum=0.999)\n",
    "    df_pfba.loc[rxns_all, rxnid + '_ko'] = pfba.fluxes[rxns_all]\n",
    "        \n",
    "    rxn.bounds = model_raw.reactions.get_by_id(rxn.id).bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pfba.to_csv('./output/Step1_pfba_iRhto1108.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate pairwise Eucledian distance (normalized by number of dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    }
   ],
   "source": [
    "df_pfba = pd.read_csv('./output/Step1_pfba_iRhto1108.csv', sep='\\t', index_col=0)\n",
    "\n",
    "for i in tqdm(df_pfba.index, leave=False):\n",
    "    for j in df_pfba.columns:\n",
    "        if abs(df_pfba.loc[i,j]) < 1e-6:\n",
    "            df_pfba.loc[i,j] = 0\n",
    "            \n",
    "rxns_zero = []\n",
    "for i in df_pfba.index:\n",
    "    if all([val == 0 for val in df_pfba.loc[i, :]]):\n",
    "        rxns_zero.append(i)\n",
    "        \n",
    "rxns = [rxn for rxn in df_pfba.index if rxn not in rxns_zero]\n",
    "df_pfba = df_pfba.loc[rxns, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/Step1_rxns_excluded.json') as f:\n",
    "    rxns_excl = json.load(f)\n",
    "rxns_check = [rxn.id for rxn in model.reactions if rxn.id not in sum(rxns_excl.values(), [])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    }
   ],
   "source": [
    "cols = ['WT'] + [i + '_ko' for i in rxns_check]\n",
    "df_pair_dist = pd.DataFrame(index=cols, columns=cols)\n",
    "for i in cols:\n",
    "    df_pair_dist.loc[i, i] = 0\n",
    "\n",
    "rxns_all = df_pfba.index.tolist()\n",
    "for i in tqdm(range(0, len(cols)-1), leave=False):\n",
    "    for j in range(1, len(cols)):\n",
    "        eu_dist = np.linalg.norm(df_pfba[cols[i]] - df_pfba[cols[j]]) / len(rxns_all)\n",
    "        df_pair_dist.loc[cols[i], cols[j]] = eu_dist\n",
    "        df_pair_dist.loc[cols[j], cols[i]] = eu_dist"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cols = ['WT'] + [i + '_ko' for i in rxns_check]\n",
    "df_pair_dist = pd.DataFrame(index=cols, columns=cols)\n",
    "for i in cols:\n",
    "    df_pair_dist.loc[i, i] = 0\n",
    "\n",
    "rxns_all = df_pfba.index.tolist()\n",
    "for i in tqdm(range(0, len(cols)-1), leave=False):\n",
    "    for j in range(1, len(cols)):\n",
    "        eu_dist = 0\n",
    "        for rxnid in rxns_all:\n",
    "            eu_dist += (df_pfba.loc[rxnid, cols[i]] - df_pfba.loc[rxnid, cols[j]]) ** 2\n",
    "        eu_dist = (eu_dist ** 0.5) / len(rxns_all)\n",
    "        \n",
    "        df_pair_dist.loc[cols[i], cols[j]] = eu_dist\n",
    "        df_pair_dist.loc[cols[j], cols[i]] = eu_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cols:\n",
    "    for j in cols:\n",
    "        if df_pair_dist.loc[i,j] < 1e-6:\n",
    "            df_pair_dist.loc[i,j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair_dist.to_csv('./output/Step1_pfba_pairwise_distance_iRhto1108_raw.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map mutants with identical flux vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair_dist = pd.read_csv('./output/Step1_pfba_pairwise_distance_iRhto1108_raw.csv',\n",
    "                           sep='\\t', index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutants = df_pair_dist.columns\n",
    "mut_identical = dict()\n",
    "mut_already_check = []\n",
    "for i in range(0, len(mutants)-1):\n",
    "    mut1 = mutants[i]\n",
    "    \n",
    "    for j in range(i+1, len(mutants)):\n",
    "        mut2 = mutants[j]\n",
    "        if mut2 in mut_already_check:\n",
    "            continue\n",
    "        \n",
    "        val = df_pair_dist.loc[mut1, mut2]\n",
    "        if val == 0:\n",
    "            mut_already_check.append(mut2)\n",
    "            if mut1 in mut_identical.keys():\n",
    "                mut_identical[mut1].append(mut2)\n",
    "            else:\n",
    "                mut_identical[mut1] = [mut2]\n",
    "                \n",
    "mut_in_identical = mut_identical.keys() + sum(mut_identical.values(), [])\n",
    "mut_unique = [mut for mut in mutants if mut not in mut_in_identical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPE_c_ko in unique mutants (flux vector is unique)\n"
     ]
    }
   ],
   "source": [
    "mut_check = 'RPE_c_ko'\n",
    "if mut_check[:-3] not in rxns_check:\n",
    "    print mut_check, 'not in mutant candidate'\n",
    "elif mut_check in mut_unique:\n",
    "    print mut_check, 'in unique mutants (flux vector is unique)'\n",
    "else:\n",
    "    for mut,val in mut_identical.items():\n",
    "        if mut_check in val:\n",
    "            print mut, val\n",
    "        if mut_check == mut:\n",
    "            print mut, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/Step1_mut_identical.json', 'w') as f:\n",
    "    f.write(json.dumps(mut_identical))\n",
    "with open('./output/Step1_mut_unique.txt', 'w') as f:\n",
    "    f.write('\\n'.join(mut_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = mut_identical.keys() + mut_unique\n",
    "idx = ['WT'] + sorted([i for i in idx if i != 'WT'])\n",
    "df_pair_dist = df_pair_dist.loc[idx, idx]\n",
    "df_pair_dist.to_csv('./output/Step1_pfba_pairwise_distance_iRhto1108.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mutants = df_pair_dist.columns\n",
    "\n",
    "muts_none_all = []\n",
    "for i in range(0, len(mutants)-1):\n",
    "    mut1 = mutants[i]\n",
    "    #print mut1 + ':',\n",
    "    \n",
    "    muts_none = []\n",
    "    for j in range(i+1, len(mutants)):\n",
    "        mut2 = mutants[j]\n",
    "        val = df_pair_dist.loc[mut1, mut2]\n",
    "        if val == 0:\n",
    "            muts_none.append(mut2)\n",
    "        \n",
    "    #print ','.join(muts_none)\n",
    "    muts_none_all += muts_none\n",
    "    \n",
    "muts_none_all = set(muts_none_all)\n",
    "\n",
    "idx = [mut for mut in df_pair_dist.index if mut not in muts_none_all]\n",
    "df_pair_dist = df_pair_dist.loc[idx, idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter pfba results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair_dist = pd.read_csv('./output/Step1_pfba_pairwise_distance_iRhto1108.csv', sep='\\t', index_col=0)\n",
    "idx = df_pair_dist.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pfba = pd.read_csv('./output/Step1_pfba_iRhto1108.csv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    }
   ],
   "source": [
    "df_pfba_filtered = df_pfba.loc[:, idx]\n",
    "\n",
    "for i in tqdm(df_pfba.index, leave=False):\n",
    "    for j in df_pfba.columns:\n",
    "        if abs(df_pfba.loc[i,j]) < 1e-6:\n",
    "            df_pfba.loc[i,j] = 0\n",
    "            \n",
    "rxns_zero = []\n",
    "for i in df_pfba.index:\n",
    "    if all([val == 0 for val in df_pfba.loc[i, :]]):\n",
    "        rxns_zero.append(i)\n",
    "        \n",
    "rxns = [rxn for rxn in df_pfba.index if rxn not in rxns_zero]\n",
    "df_pfba_filtered = df_pfba.loc[rxns, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pfba_filtered.to_csv('./output/pfba_iRhto1108_filtered.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7541272865685728"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pfba_filtered.loc['Biomass_Rt_Clim', :].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
